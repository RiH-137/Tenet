{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789d0ed6-8cc7-4c90-a66d-c3625ae72b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565786cd-9666-4265-b141-8dfde755644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\program files\\drag software\\anaconda\\lib\\site-packages (2.17.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: opencv-python in c:\\program files\\drag software\\anaconda\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: moviepy in c:\\program files\\drag software\\anaconda\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\drag software\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.5)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from moviepy) (4.66.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\drag software\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow opencv-python moviepy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e30c89-13a8-4fab-b6dc-dd7faa7ca5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac80df3-c262-4631-98a5-4bd8d3afb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\"), frame)\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n",
    "# Example usage\n",
    "extract_frames(r\"C:\\Users\\101ri\\OneDrive\\Desktop\\deep fake detector\\Notebook\\Celeb-real\\id0_0000.mp4\", \"Celeb-real/frames\")\n",
    "extract_frames(r\"C:\\Users\\101ri\\OneDrive\\Desktop\\deep fake detector\\Notebook\\Celeb-synthesis\\id0_id1_0000.mp4\", \"Celeb-synthesis/frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf64b50-fd7d-4a3c-86b5-a7401cf291ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0856167-10b8-4cd5-b2bc-332a1be66299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544ae995-30a3-4cd7-a4f3-c685229d0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images_from_folder(folder, label, image_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "real_images, real_labels = load_images_from_folder(\"Celeb-real/frames\", label=0)  # 0 for real\n",
    "fake_images, fake_labels = load_images_from_folder(\"Celeb-synthesis/frames\", label=1)  # 1 for fake\n",
    "\n",
    "X = np.array(real_images + fake_images)\n",
    "y = np.array(real_labels + fake_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c52fe-6d32-4d6e-8a43-76073b328285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77e18cd-9a08-4e3b-afee-bb52e87a0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### frames extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f469f49-a733-4e90-b370-7fd75a9cb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d91cc91-f7f6-4092-b9dd-6c205a6327c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(video_path, frame_count=30):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    frames = []\n",
    "    duration = clip.duration\n",
    "    for i in range(frame_count):\n",
    "        frame = clip.get_frame(i * duration / frame_count)\n",
    "        frame = cv2.resize(frame, (128, 128))\n",
    "        frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "818a7f12-ed0f-4721-b2d2-0afcddba1e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 97   0   0]\n",
      "   [ 95   0   0]\n",
      "   [ 90   1   0]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 29  16   9]\n",
      "   [ 33  20  13]]\n",
      "\n",
      "  [[100   2   1]\n",
      "   [101   3   2]\n",
      "   [ 99   1   2]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 29  16   9]\n",
      "   [ 33  20  13]]\n",
      "\n",
      "  [[ 86   3   0]\n",
      "   [ 87   4   0]\n",
      "   [ 88   2   0]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 29  16   9]\n",
      "   [ 33  20  13]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]]\n",
      "\n",
      "  [[ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]]\n",
      "\n",
      "  [[ 62   0   0]\n",
      "   [ 62   0   0]\n",
      "   [ 62   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 31  10   6]\n",
      "   [ 31  10   6]]]\n",
      "\n",
      "\n",
      " [[[ 96   0   0]\n",
      "   [ 97   1   1]\n",
      "   [ 91   0   1]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 31  15   9]\n",
      "   [ 30  19  12]]\n",
      "\n",
      "  [[103   1   3]\n",
      "   [104   2   4]\n",
      "   [ 99   0   1]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 31  15   9]\n",
      "   [ 30  19  12]]\n",
      "\n",
      "  [[ 91   4   1]\n",
      "   [ 90   3   1]\n",
      "   [ 87   3   0]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 31  15   9]\n",
      "   [ 31  20  13]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]]\n",
      "\n",
      "  [[ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]]\n",
      "\n",
      "  [[ 62   0   0]\n",
      "   [ 62   0   0]\n",
      "   [ 62   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 31  10   6]\n",
      "   [ 31  10   6]]]\n",
      "\n",
      "\n",
      " [[[100   1   2]\n",
      "   [100   1   2]\n",
      "   [ 90   1   3]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 31  15   9]\n",
      "   [ 30  19  12]]\n",
      "\n",
      "  [[104   4   6]\n",
      "   [104   4   6]\n",
      "   [ 97   1   2]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 31  15   9]\n",
      "   [ 30  19  12]]\n",
      "\n",
      "  [[ 87   2   0]\n",
      "   [ 90   5   2]\n",
      "   [ 86   3   0]\n",
      "   ...\n",
      "   [ 29  13   7]\n",
      "   [ 31  15   9]\n",
      "   [ 31  20  13]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]]\n",
      "\n",
      "  [[ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   [ 65   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]\n",
      "   [ 29  11   6]]\n",
      "\n",
      "  [[ 62   0   0]\n",
      "   [ 62   0   0]\n",
      "   [ 63   0   0]\n",
      "   ...\n",
      "   [ 29  11   6]\n",
      "   [ 31  10   6]\n",
      "   [ 31  10   6]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 16   1  14]\n",
      "   [  5   0  45]\n",
      "   [  6   0  54]\n",
      "   ...\n",
      "   [112  87  67]\n",
      "   [ 72  52  32]\n",
      "   [ 76  51  32]]\n",
      "\n",
      "  [[ 14   1  15]\n",
      "   [  3   0  53]\n",
      "   [  1   0  71]\n",
      "   ...\n",
      "   [113  82  62]\n",
      "   [ 72  52  32]\n",
      "   [ 77  52  33]]\n",
      "\n",
      "  [[ 12   0  15]\n",
      "   [  2   0  58]\n",
      "   [  0   0  75]\n",
      "   ...\n",
      "   [114  81  60]\n",
      "   [ 72  52  32]\n",
      "   [ 77  52  33]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 46   0   2]\n",
      "   [ 26   0  12]\n",
      "   [ 13   0  11]\n",
      "   ...\n",
      "   [ 41  22  10]\n",
      "   [ 41  20   7]\n",
      "   [ 54  28  16]]\n",
      "\n",
      "  [[ 47   0   1]\n",
      "   [ 29   0   8]\n",
      "   [ 15   0  10]\n",
      "   ...\n",
      "   [ 44  25  13]\n",
      "   [ 41  20   7]\n",
      "   [ 54  28  16]]\n",
      "\n",
      "  [[ 50   0   2]\n",
      "   [ 28   0   6]\n",
      "   [ 12   1  10]\n",
      "   ...\n",
      "   [ 57  36  22]\n",
      "   [ 54  33  20]\n",
      "   [ 61  39  26]]]\n",
      "\n",
      "\n",
      " [[[  2   0  45]\n",
      "   [  0   0  73]\n",
      "   [  1   0  70]\n",
      "   ...\n",
      "   [128  86  69]\n",
      "   [ 72  50  30]\n",
      "   [ 76  52  33]]\n",
      "\n",
      "  [[  0   0  49]\n",
      "   [  0   0  76]\n",
      "   [  0   0  72]\n",
      "   ...\n",
      "   [132  91  73]\n",
      "   [ 70  50  30]\n",
      "   [ 76  52  33]]\n",
      "\n",
      "  [[  3   0  47]\n",
      "   [  0   0  70]\n",
      "   [  0   0  74]\n",
      "   ...\n",
      "   [137  95  78]\n",
      "   [ 70  50  30]\n",
      "   [ 76  52  33]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 30   0  10]\n",
      "   [ 15   1   6]\n",
      "   [ 12   1  10]\n",
      "   ...\n",
      "   [ 41  20   9]\n",
      "   [ 41  19  11]\n",
      "   [ 41  20   8]]\n",
      "\n",
      "  [[ 29   1   9]\n",
      "   [ 15   0   8]\n",
      "   [ 12   1  10]\n",
      "   ...\n",
      "   [ 41  20   9]\n",
      "   [ 41  20  10]\n",
      "   [ 41  20   7]]\n",
      "\n",
      "  [[ 33   0   6]\n",
      "   [ 11   0   7]\n",
      "   [ 12   1  10]\n",
      "   ...\n",
      "   [ 51  30  15]\n",
      "   [ 45  24  12]\n",
      "   [ 47  26  13]]]\n",
      "\n",
      "\n",
      " [[[  0   0  73]\n",
      "   [  0   0  75]\n",
      "   [  0   0  78]\n",
      "   ...\n",
      "   [106  39  26]\n",
      "   [115  79  61]\n",
      "   [ 74  50  28]]\n",
      "\n",
      "  [[  0   0  73]\n",
      "   [  0   0  76]\n",
      "   [  0   0  79]\n",
      "   ...\n",
      "   [104  39  25]\n",
      "   [114  79  61]\n",
      "   [ 73  50  28]]\n",
      "\n",
      "  [[  2   0  36]\n",
      "   [  2   0  41]\n",
      "   [  5   0  39]\n",
      "   ...\n",
      "   [101  41  25]\n",
      "   [113  82  61]\n",
      "   [ 71  51  28]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 16   2  10]\n",
      "   [ 12   1  10]\n",
      "   [ 12   1  10]\n",
      "   ...\n",
      "   [ 41  19  11]\n",
      "   [ 42  21  10]\n",
      "   [ 42  21  10]]\n",
      "\n",
      "  [[ 14   0   7]\n",
      "   [ 11   0   9]\n",
      "   [ 13   0  10]\n",
      "   ...\n",
      "   [ 41  20  10]\n",
      "   [ 42  21  10]\n",
      "   [ 42  21  10]]\n",
      "\n",
      "  [[ 11   0   6]\n",
      "   [ 11   0   6]\n",
      "   [ 12   0  11]\n",
      "   ...\n",
      "   [ 47  25  12]\n",
      "   [ 43  22  11]\n",
      "   [ 43  22  11]]]]\n"
     ]
    }
   ],
   "source": [
    "print(extract_frames_from_video(r\"C:\\Users\\101ri\\OneDrive\\Desktop\\deep fake detector\\Notebook\\Celeb-real\\id0_0000.mp4\", 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf1506-5e1b-4063-8653-964bc11bcb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f98110-ad86-4f4b-9b90-2d55a48cafb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6d890d5-afad-4dde-9937-2838670f38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127b0cb-178b-41d6-96da-1c48778429a9",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3562fe9e-f12a-4618-afc8-0b8dfd2d50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d83f69-0164-41fb-8546-67def321b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)  # Adjust based on your frame size\n",
    "cnn_model = build_cnn_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a74c60c-9409-4d30-9c9b-5c8054f6baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5618e2-61fc-4aec-b606-2e500c5c392f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - accuracy: 0.5589 - loss: 62.7976 - val_accuracy: 0.5467 - val_loss: 0.6864\n",
      "Epoch 2/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.4647 - loss: 0.6943 - val_accuracy: 0.5867 - val_loss: 0.6846\n",
      "Epoch 3/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.5930 - loss: 0.6776 - val_accuracy: 0.4622 - val_loss: 0.8710\n",
      "Epoch 4/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.6021 - loss: 0.7210 - val_accuracy: 0.5422 - val_loss: 0.6836\n",
      "Epoch 5/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5344 - loss: 0.6849 - val_accuracy: 0.5511 - val_loss: 0.6788\n",
      "Epoch 6/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.5181 - loss: 0.6881 - val_accuracy: 0.5511 - val_loss: 0.6750\n",
      "Epoch 7/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.5507 - loss: 0.6830 - val_accuracy: 0.6400 - val_loss: 0.6661\n",
      "Epoch 8/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5739 - loss: 0.6829 - val_accuracy: 0.5111 - val_loss: 0.6936\n",
      "Epoch 9/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.5643 - loss: 0.6829 - val_accuracy: 0.5200 - val_loss: 0.6925\n",
      "Epoch 10/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.6186 - loss: 0.6767 - val_accuracy: 0.5022 - val_loss: 0.6901\n",
      "Epoch 11/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.6167 - loss: 0.6716 - val_accuracy: 0.5067 - val_loss: 0.6965\n",
      "Epoch 12/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.6251 - loss: 0.6550 - val_accuracy: 0.4978 - val_loss: 0.7148\n",
      "Epoch 13/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.6256 - loss: 0.6519 - val_accuracy: 0.5289 - val_loss: 0.6703\n",
      "Epoch 14/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5654 - loss: 0.7056 - val_accuracy: 0.5822 - val_loss: 0.6620\n",
      "Epoch 15/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.6994 - loss: 0.6513 - val_accuracy: 0.6978 - val_loss: 0.6270\n",
      "Epoch 16/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.6585 - loss: 0.6381 - val_accuracy: 0.5467 - val_loss: 0.5800\n",
      "Epoch 17/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.6279 - loss: 0.6049 - val_accuracy: 0.4622 - val_loss: 0.7169\n",
      "Epoch 18/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.6074 - loss: 0.6609 - val_accuracy: 0.8533 - val_loss: 0.5590\n",
      "Epoch 19/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.7882 - loss: 0.5661 - val_accuracy: 0.4622 - val_loss: 0.7666\n",
      "Epoch 20/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.5917 - loss: 0.6690 - val_accuracy: 0.7956 - val_loss: 0.3935\n",
      "Epoch 21/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.6360 - loss: 0.5806 - val_accuracy: 0.4622 - val_loss: 0.7633\n",
      "Epoch 22/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5235 - loss: 0.7187 - val_accuracy: 0.5067 - val_loss: 0.7112\n",
      "Epoch 23/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.5802 - loss: 0.6743 - val_accuracy: 0.8711 - val_loss: 0.4680\n",
      "Epoch 24/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.8194 - loss: 0.4406 - val_accuracy: 0.8933 - val_loss: 0.2873\n",
      "Epoch 25/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9235 - loss: 0.3530 - val_accuracy: 0.9600 - val_loss: 0.2296\n",
      "Epoch 26/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.9904 - loss: 0.2298 - val_accuracy: 1.0000 - val_loss: 0.1449\n",
      "Epoch 27/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.9979 - loss: 0.1544 - val_accuracy: 1.0000 - val_loss: 0.1569\n",
      "Epoch 28/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.9869 - loss: 0.1262 - val_accuracy: 1.0000 - val_loss: 0.0746\n",
      "Epoch 29/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.9978 - loss: 0.0756 - val_accuracy: 0.9956 - val_loss: 0.0636\n",
      "Epoch 30/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.9923 - loss: 0.0744 - val_accuracy: 1.0000 - val_loss: 0.0353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23531ba3860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "cnn_model.fit(X_train, y_train, epochs=30, batch_size=18, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca151469-c061-4454-a707-be42238be55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "898f1581-b7ed-417f-a8d5-c103e148d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0447\n"
     ]
    }
   ],
   "source": [
    "# model evalution\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3abd6e8b-d075-4529-a2d6-2daf38937229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnn Model Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Cnn Model Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8452dd9a-b5d4-42e3-a82c-9fd14eea5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "cnn_model.save(\"cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447e37f-9965-454b-b039-1a11c590352f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ed7b530-ed98-4203-b149-3525db51cc24",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "462c83bc-f908-4a0c-8208-0b9ce3da0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, TimeDistributed, Bidirectional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef9046-8199-4d9d-8485-655d80bc4c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57ca8d-2851-4055-8e72-0c259080fe13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e427b7c4-948a-40ef-a534-e22b0771234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train has shape (num_samples, 128, 128, 3)\n",
    "# and you want to create sequences of 10 frames\n",
    "num_frames_per_sequence = 10\n",
    "\n",
    "# Calculate the number of sequences you can create\n",
    "num_sequences = len(X_train) // num_frames_per_sequence\n",
    "\n",
    "# Reshape data into sequences\n",
    "X_train_lstm = X_train[:num_sequences * num_frames_per_sequence]\n",
    "X_train_lstm = X_train_lstm.reshape((num_sequences, num_frames_per_sequence, 128, 128, 3))\n",
    "\n",
    "# Repeat similarly for X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71b26e-dc63-464f-b6cf-e4224864896c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "400afdaa-d60e-45e6-9142-fe40abb5d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape)),\n",
    "        TimeDistributed(layers.MaxPooling2D((2, 2))),\n",
    "        TimeDistributed(layers.Flatten()),\n",
    "        Bidirectional(layers.LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "        Bidirectional(layers.LSTM(50, dropout=0.2, recurrent_dropout=0.2)),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "686dc56d-00f6-45e8-b0d3-1f2a4657cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (10, 128, 128, 3)  # Example with 10 frames per sequence\n",
    "lstm_model = build_lstm_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "341ce2f3-c167-4f4f-8ee7-c05fa3d15c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.4867 - loss: 0.7285 - val_accuracy: 0.5333 - val_loss: 0.7105\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5300 - loss: 0.7321 - val_accuracy: 0.5333 - val_loss: 0.7007\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4928 - loss: 0.7098 - val_accuracy: 0.5333 - val_loss: 0.6930\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6418 - loss: 0.6601 - val_accuracy: 0.5333 - val_loss: 0.7020\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6393 - loss: 0.6422 - val_accuracy: 0.5333 - val_loss: 0.6906\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4923 - loss: 0.7015 - val_accuracy: 0.5333 - val_loss: 0.6918\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4377 - loss: 0.7053 - val_accuracy: 0.5333 - val_loss: 0.7003\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5958 - loss: 0.6713 - val_accuracy: 0.5333 - val_loss: 0.6995\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5579 - loss: 0.6773 - val_accuracy: 0.5333 - val_loss: 0.7056\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5580 - loss: 0.6825 - val_accuracy: 0.5333 - val_loss: 0.7016\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5386 - loss: 0.6704 - val_accuracy: 0.5333 - val_loss: 0.7007\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6009 - loss: 0.6943 - val_accuracy: 0.5333 - val_loss: 0.7053\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5755 - loss: 0.6684 - val_accuracy: 0.5333 - val_loss: 0.7053\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6574 - loss: 0.6569 - val_accuracy: 0.5333 - val_loss: 0.6996\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5103 - loss: 0.7101 - val_accuracy: 0.5333 - val_loss: 0.7000\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4987 - loss: 0.6885 - val_accuracy: 0.5333 - val_loss: 0.7057\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5823 - loss: 0.6755 - val_accuracy: 0.5333 - val_loss: 0.7026\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5497 - loss: 0.6817 - val_accuracy: 0.5333 - val_loss: 0.7089\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5664 - loss: 0.6953 - val_accuracy: 0.5333 - val_loss: 0.6989\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4961 - loss: 0.6831 - val_accuracy: 0.5333 - val_loss: 0.6970\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6507 - loss: 0.6367 - val_accuracy: 0.5333 - val_loss: 0.7042\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5827 - loss: 0.6861 - val_accuracy: 0.5333 - val_loss: 0.6918\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5420 - loss: 0.6886 - val_accuracy: 0.5333 - val_loss: 0.6922\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5843 - loss: 0.6775 - val_accuracy: 0.5333 - val_loss: 0.6955\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5569 - loss: 0.6700 - val_accuracy: 0.5333 - val_loss: 0.6935\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6460 - loss: 0.6662 - val_accuracy: 0.5333 - val_loss: 0.6912\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4443 - loss: 0.7200 - val_accuracy: 0.5333 - val_loss: 0.6920\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5702 - loss: 0.6925 - val_accuracy: 0.5333 - val_loss: 0.7003\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.5901 - loss: 0.6790 - val_accuracy: 0.5333 - val_loss: 0.6962\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6469 - loss: 0.6755 - val_accuracy: 0.5333 - val_loss: 0.6962\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3958 - loss: 0.7152 - val_accuracy: 0.5333 - val_loss: 0.6913\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5853 - loss: 0.6795 - val_accuracy: 0.5333 - val_loss: 0.7023\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5041 - loss: 0.7161 - val_accuracy: 0.5333 - val_loss: 0.7096\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5770 - loss: 0.6772 - val_accuracy: 0.5333 - val_loss: 0.7099\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5940 - loss: 0.6698 - val_accuracy: 0.5333 - val_loss: 0.6974\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4801 - loss: 0.7063 - val_accuracy: 0.5333 - val_loss: 0.6913\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5317 - loss: 0.6992 - val_accuracy: 0.5333 - val_loss: 0.7003\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6560 - loss: 0.6859 - val_accuracy: 0.5333 - val_loss: 0.7067\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5776 - loss: 0.6838 - val_accuracy: 0.5333 - val_loss: 0.6927\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5274 - loss: 0.6976 - val_accuracy: 0.5333 - val_loss: 0.6926\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5159 - loss: 0.6991 - val_accuracy: 0.5333 - val_loss: 0.6909\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3926 - loss: 0.7082 - val_accuracy: 0.5333 - val_loss: 0.6913\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5743 - loss: 0.6884 - val_accuracy: 0.5333 - val_loss: 0.6984\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5678 - loss: 0.6845 - val_accuracy: 0.5333 - val_loss: 0.6958\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6054 - loss: 0.6805 - val_accuracy: 0.5333 - val_loss: 0.6932\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4812 - loss: 0.7035 - val_accuracy: 0.5333 - val_loss: 0.6917\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4797 - loss: 0.6856 - val_accuracy: 0.5333 - val_loss: 0.6960\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5061 - loss: 0.7171 - val_accuracy: 0.5333 - val_loss: 0.6974\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4958 - loss: 0.6982 - val_accuracy: 0.5333 - val_loss: 0.6976\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4799 - loss: 0.7018 - val_accuracy: 0.5333 - val_loss: 0.6964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2353d532810>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for LSTM (e.g., sequences of frames)\n",
    "# X_train_lstm, X_test_lstm need to be prepared with sequences of frames\n",
    "\n",
    "# Train the model\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=8, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09049019-37ab-42c6-b720-d90b64b17988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "lstm_model.save(\"lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ca3a6-f4c7-4ec7-935c-d0ee2f4dff96",
   "metadata": {},
   "source": [
    "Almost 60-65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f275f6b-d242-42fd-b694-09876745a734",
   "metadata": {},
   "source": [
    "### Capsule Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ec2eddf-c009-4986-8ddf-b648b4f10526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Reshape, Dense, Lambda, TimeDistributed, Flatten, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "046861ac-a544-4e5a-943c-2b706302696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## forcing tensorflow to use gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a409df8-1050-4e08-9717-ec5b5f3b0fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Drag Software\\Anaconda\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Drag Software\\Anaconda\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## clear previous session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25be7527-34c5-479c-95b8-edf88015f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom squash function for capsule layers\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return s_squared_norm / (1. + s_squared_norm) * x / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6b9f3-c249-45c2-98b1-af5aa0c314a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2510b92-120f-4b69-b0b7-f24dfc462df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## capsule network model\n",
    "def build_capsule_network(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = TimeDistributed(Conv2D(128, (9, 9), activation='relu'))(inputs)  # Reduced filters\n",
    "    primary_caps = TimeDistributed(Conv2D(8 * 16, (9, 9), strides=2, padding='valid'))(conv1)  # Reduced filters\n",
    "    primary_caps = TimeDistributed(Reshape((-1, 8)))(primary_caps)\n",
    "    primary_caps = TimeDistributed(Lambda(squash))(primary_caps)\n",
    "    \n",
    "    primary_caps_flat = TimeDistributed(Flatten())(primary_caps)\n",
    "    lstm_output = LSTM(50)(primary_caps_flat)\n",
    "    \n",
    "    caps_output = Dense(1, activation='sigmoid')(lstm_output)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=caps_output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e5e947-8cfe-4820-966c-64fb7f6d5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(300, 128, 128, 3)  # Reduced number of frames\n",
    "y_train = np.random.randint(0, 2, size=(30,))  # Corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c590d3ec-0c8e-4d02-81d5-c6e0a398542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshape the data into sequences of frames\n",
    "num_frames_per_sequence = 10\n",
    "num_sequences = len(X_train) // num_frames_per_sequence\n",
    "\n",
    "X_train_lstm = X_train[:num_sequences * num_frames_per_sequence].reshape(\n",
    "    (num_sequences, num_frames_per_sequence, 128, 128, 3)\n",
    ")\n",
    "\n",
    "y_train_lstm = y_train[:num_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfc282b-87f2-4d64-8bee-a896799038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (num_frames_per_sequence, 128, 128, 3)\n",
    "capsule_model = build_capsule_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f49dc407-758a-41d9-b84a-c8a2458e352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,232</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,232</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">401408</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">80,291,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m31,232\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m1,327,232\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_2 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50176\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_3 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50176\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_4 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m401408\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │      \u001b[38;5;34m80,291,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,650,315</span> (311.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,650,315\u001b[0m (311.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,650,315</span> (311.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,650,315\u001b[0m (311.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "capsule_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca6ab4c4-d3e4-40eb-a41b-2a5ec3453873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 14s/step - accuracy: 0.5104 - loss: 1.4215 - val_accuracy: 0.5000 - val_loss: 1.6260\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3958 - loss: 1.9515 - val_accuracy: 0.5000 - val_loss: 1.6052\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3958 - loss: 1.9254 - val_accuracy: 0.5000 - val_loss: 1.5822\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4115 - loss: 1.8487 - val_accuracy: 0.5000 - val_loss: 1.5584\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4740 - loss: 1.6303 - val_accuracy: 0.5000 - val_loss: 1.5346\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3958 - loss: 1.8382 - val_accuracy: 0.5000 - val_loss: 1.5104\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3802 - loss: 1.8544 - val_accuracy: 0.5000 - val_loss: 1.4863\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14s/step - accuracy: 0.3490 - loss: 1.9135 - val_accuracy: 0.5000 - val_loss: 1.4622\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4427 - loss: 1.6169 - val_accuracy: 0.5000 - val_loss: 1.4389\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14s/step - accuracy: 0.3958 - loss: 1.7207 - val_accuracy: 0.5000 - val_loss: 1.4156\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13s/step - accuracy: 0.4427 - loss: 1.5642 - val_accuracy: 0.5000 - val_loss: 1.3927\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.5365 - loss: 1.2888 - val_accuracy: 0.5000 - val_loss: 1.3704\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3646 - loss: 1.7169 - val_accuracy: 0.5000 - val_loss: 1.3475\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3646 - loss: 1.6872 - val_accuracy: 0.5000 - val_loss: 1.3252\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4271 - loss: 1.5015 - val_accuracy: 0.5000 - val_loss: 1.3036\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3802 - loss: 1.5908 - val_accuracy: 0.5000 - val_loss: 1.2818\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4427 - loss: 1.4129 - val_accuracy: 0.5000 - val_loss: 1.2608\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4583 - loss: 1.3525 - val_accuracy: 0.5000 - val_loss: 1.2401\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3802 - loss: 1.5096 - val_accuracy: 0.5000 - val_loss: 1.2193\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4271 - loss: 1.3769 - val_accuracy: 0.5000 - val_loss: 1.1990\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3333 - loss: 1.5595 - val_accuracy: 0.5000 - val_loss: 1.1788\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3490 - loss: 1.4974 - val_accuracy: 0.5000 - val_loss: 1.1592\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4271 - loss: 1.3064 - val_accuracy: 0.5000 - val_loss: 1.1404\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4583 - loss: 1.2200 - val_accuracy: 0.5000 - val_loss: 1.1219\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4115 - loss: 1.2933 - val_accuracy: 0.5000 - val_loss: 1.1035\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3958 - loss: 1.3009 - val_accuracy: 0.5000 - val_loss: 1.0853\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3646 - loss: 1.3373 - val_accuracy: 0.5000 - val_loss: 1.0674\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4427 - loss: 1.1681 - val_accuracy: 0.5000 - val_loss: 1.0504\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4583 - loss: 1.1200 - val_accuracy: 0.5000 - val_loss: 1.0337\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4271 - loss: 1.1564 - val_accuracy: 0.5000 - val_loss: 1.0172\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.5052 - loss: 1.0033 - val_accuracy: 0.5000 - val_loss: 1.0017\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4271 - loss: 1.1179 - val_accuracy: 0.5000 - val_loss: 0.9860\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3802 - loss: 1.1747 - val_accuracy: 0.5000 - val_loss: 0.9706\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4896 - loss: 0.9821 - val_accuracy: 0.5000 - val_loss: 0.9563\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.5052 - loss: 0.9437 - val_accuracy: 0.5000 - val_loss: 0.9424\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3958 - loss: 1.0922 - val_accuracy: 0.5000 - val_loss: 0.9284\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3490 - loss: 1.1409 - val_accuracy: 0.5000 - val_loss: 0.9146\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4115 - loss: 1.0336 - val_accuracy: 0.5000 - val_loss: 0.9018\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3802 - loss: 1.0590 - val_accuracy: 0.5000 - val_loss: 0.8893\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4271 - loss: 0.9805 - val_accuracy: 0.5000 - val_loss: 0.8775\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3646 - loss: 1.0446 - val_accuracy: 0.5000 - val_loss: 0.8659\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13s/step - accuracy: 0.4115 - loss: 0.9702 - val_accuracy: 0.5000 - val_loss: 0.8550\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3958 - loss: 0.9740 - val_accuracy: 0.5000 - val_loss: 0.8444\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4427 - loss: 0.9059 - val_accuracy: 0.5000 - val_loss: 0.8345\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3646 - loss: 0.9794 - val_accuracy: 0.5000 - val_loss: 0.8245\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.3490 - loss: 0.9809 - val_accuracy: 0.5000 - val_loss: 0.8152\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4427 - loss: 0.8702 - val_accuracy: 0.5000 - val_loss: 0.8067\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - accuracy: 0.4896 - loss: 0.8137 - val_accuracy: 0.5000 - val_loss: 0.7987\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4115 - loss: 0.8793 - val_accuracy: 0.5000 - val_loss: 0.7908\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.4115 - loss: 0.8682 - val_accuracy: 0.5000 - val_loss: 0.7832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23537837b60>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capsule_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00ded1c2-7cad-4715-8560-ceb68695af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.4333 - loss: 0.8407\n",
      "Cnn Model Test Accuracy: 0.4333333373069763\n"
     ]
    }
   ],
   "source": [
    "# model evalution\n",
    "loss, accuracy = capsule_model.evaluate(X_train_lstm, y_train_lstm)\n",
    "print(f'Cnn Model Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f69746ff-55cf-4b8e-b7cd-d2b97a2ece91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "capsule_model.save(\"capsule_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a96ad318-c30e-4687-9043-458573ef3244",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop123' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop123\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop123' is not defined"
     ]
    }
   ],
   "source": [
    "stop123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b92bf3-3e42-468c-b01c-471fe864c57e",
   "metadata": {},
   "source": [
    "### Gans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e508d75-e294-405e-b0cb-87b9c9361c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, LeakyReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5098efc-daa6-46b9-875d-0c72e2a4184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe55130-8e76-4938-bd44-1576ac701149",
   "metadata": {},
   "source": [
    "### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be762d6-d434-443a-8cc0-44ea86609778",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 20  # Example latent dimension\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    model_gen = Sequential()\n",
    "    \n",
    "    # Fully connected layer\n",
    "    model_gen.add(Dense(16 * 16 * 256, input_dim=latent_dim))\n",
    "    model_gen.add(Reshape((16, 16, 256)))\n",
    "    \n",
    "    # Transposed Convolutional Layers to upscale to (128, 128, 3)\n",
    "    model_gen.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model_gen.add(BatchNormalization())\n",
    "    model_gen.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model_gen.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model_gen.add(BatchNormalization())\n",
    "    model_gen.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model_gen.add(Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh'))\n",
    "    \n",
    "    return model_gen\n",
    "\n",
    "generator = build_generator(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38363d-4dbc-463b-b080-d0adbf60bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape=(128, 128, 3)):\n",
    "    model_dis = Sequential()\n",
    "    \n",
    "    # Convolutional Layers\n",
    "    model_dis.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model_dis.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model_dis.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model_dis.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model_dis.add(Flatten())\n",
    "    model_dis.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation\n",
    "    \n",
    "    return model_dis\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec9fb2-9228-4ea9-b1f5-b73daa434cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebac7f0-be79-43df-87a5-eb81ffe21714",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build and compile ghans\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # Ensure the discriminator is not trainable within the GAN\n",
    "    \n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    img = generator(gan_input)\n",
    "    gan_output = discriminator(img)\n",
    "    \n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    return gan\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1bebc1-3f45-4f07-b848-cb4da019c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa6843-ebf1-4f4f-aeec-bcfebdedc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_real_samples(X_train, n_samples):\n",
    "    idx = np.random.randint(0, X_train.shape[0], n_samples)\n",
    "    X = X_train[idx]\n",
    "    y = np.ones((n_samples, 1))  # Label as real (1)\n",
    "    return X, y\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))  # Label as fake (0)\n",
    "    return X, y\n",
    "\n",
    "def save_plot(examples, epoch, n=5):\n",
    "    examples = (examples + 1) / 2.0  # Scale from [-1, 1] to [0, 1]\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i])\n",
    "    plt.savefig(f\"generated_plot_e{epoch+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def train_gan(gan, generator, discriminator, X_train, latent_dim, n_epochs=100, n_batch=64, eval_interval=20):\n",
    "    batch_per_epoch = X_train.shape[0] // n_batch\n",
    "    half_batch = n_batch // 2\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for _ in range(batch_per_epoch):\n",
    "            # Train Discriminator on real and fake images\n",
    "            X_real, y_real = generate_real_samples(X_train, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)\n",
    "            d_loss_real = discriminator.train_on_batch(X_real, y_real)\n",
    "            d_loss_fake = discriminator.train_on_batch(X_fake, y_fake)\n",
    "\n",
    "            # Train Generator via the GAN\n",
    "            x_gan = np.random.randn(latent_dim * n_batch)\n",
    "            x_gan = x_gan.reshape(n_batch, latent_dim)\n",
    "            y_gan = np.ones((n_batch, 1))  # Attempt to fool the discriminator\n",
    "            g_loss = gan.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # Evaluate and save model performance at set intervals\n",
    "        if (epoch + 1) % eval_interval == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{n_epochs} - D loss real: {d_loss_real}, D loss fake: {d_loss_fake}, G loss: {g_loss}\")\n",
    "            X_fake, _ = generate_fake_samples(generator, latent_dim, 25)\n",
    "            save_plot(X_fake, epoch)\n",
    "\n",
    "# Assume X_train is your training dataset loaded here\n",
    "# X_train = ...\n",
    "\n",
    "train_gan(gan, generator, discriminator, X_train, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928039b-db9c-418c-a74d-22ab44e7670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gan.save('model_gan.h5')\n",
    "model_dis.save('model_dis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a18f50-ad53-42d3-bd10-e29c05285090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202594e-779c-478a-8cb9-0a915a4cd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ad732-10d0-475d-8bb8-fefbf9fe9603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7fdb3-230d-4271-95ca-790afc4792fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b54289-54df-401e-ba69-f36db85bf5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3a343-bcbb-4d3c-a60a-604b53df3b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180984c-223a-4ce7-9967-6de72371b141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8eab0-45e3-4e46-95c0-bface418088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94071ff-3b3b-4948-9574-3100b4683311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a4c7ac7-dfe8-4218-a370-7b108b0147b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frame_sequences(frames, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(frames) - sequence_length + 1):\n",
    "        sequences.append(frames[i:i + sequence_length])\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9047baa4-3c05-4eae-8bc0-d45482efd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length (e.g., 10 frames per sequence)\n",
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc87157a-93fb-4de9-9d7e-709859fd8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequential data for LSTM\n",
    "X_train_lstm = create_frame_sequences(X_train, sequence_length)\n",
    "X_test_lstm = create_frame_sequences(X_test, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12ca1c59-bb0f-4e78-8d3a-34a8da2e1010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ 98.,   0.,   0.],\n",
       "          [ 98.,   0.,   0.],\n",
       "          [ 90.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  16.,   8.],\n",
       "          [ 29.,  18.,  12.]],\n",
       "\n",
       "         [[104.,   1.,   2.],\n",
       "          [104.,   1.,   2.],\n",
       "          [100.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  17.,   9.],\n",
       "          [ 29.,  18.,  12.]],\n",
       "\n",
       "         [[ 88.,   5.,   0.],\n",
       "          [ 88.,   5.,   0.],\n",
       "          [ 85.,   4.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  16.,   8.],\n",
       "          [ 30.,  19.,  13.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 28.,  11.,   4.],\n",
       "          [ 28.,  11.,   4.]]],\n",
       "\n",
       "\n",
       "        [[[ 38.,   4.,   2.],\n",
       "          [ 36.,   5.,   3.],\n",
       "          [ 30.,   4.,   5.],\n",
       "          ...,\n",
       "          [103.,  52.,  31.],\n",
       "          [100.,  54.,  31.],\n",
       "          [101.,  56.,  33.]],\n",
       "\n",
       "         [[ 38.,   4.,   5.],\n",
       "          [ 36.,   4.,   7.],\n",
       "          [ 30.,   4.,   5.],\n",
       "          ...,\n",
       "          [105.,  54.,  35.],\n",
       "          [103.,  56.,  36.],\n",
       "          [108.,  63.,  40.]],\n",
       "\n",
       "         [[ 36.,   1.,   5.],\n",
       "          [ 34.,   1.,   8.],\n",
       "          [ 30.,   4.,   5.],\n",
       "          ...,\n",
       "          [116.,  80.,  58.],\n",
       "          [111.,  80.,  52.],\n",
       "          [114.,  83.,  54.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 58.,   0.,   3.],\n",
       "          ...,\n",
       "          [ 66.,  42.,  30.],\n",
       "          [ 69.,  42.,  31.],\n",
       "          [ 74.,  48.,  35.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 58.,   0.,   3.],\n",
       "          ...,\n",
       "          [ 44.,  20.,   8.],\n",
       "          [ 47.,  20.,   9.],\n",
       "          [ 72.,  49.,  35.]],\n",
       "\n",
       "         [[ 61.,   0.,   0.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          [ 55.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 47.,  18.,  10.],\n",
       "          [ 47.,  23.,  11.],\n",
       "          [ 60.,  37.,  23.]]],\n",
       "\n",
       "\n",
       "        [[[ 26.,   1.,   7.],\n",
       "          [ 19.,   2.,  12.],\n",
       "          [ 11.,   1.,  10.],\n",
       "          ...,\n",
       "          [124.,  89.,  67.],\n",
       "          [109.,  87.,  63.],\n",
       "          [102.,  82.,  55.]],\n",
       "\n",
       "         [[ 26.,   1.,   5.],\n",
       "          [ 18.,   1.,   9.],\n",
       "          [ 11.,   1.,   9.],\n",
       "          ...,\n",
       "          [ 68.,  52.,  27.],\n",
       "          [ 70.,  53.,  27.],\n",
       "          [ 76.,  56.,  31.]],\n",
       "\n",
       "         [[ 25.,   0.,   3.],\n",
       "          [ 17.,   0.,   6.],\n",
       "          [ 11.,   0.,  19.],\n",
       "          ...,\n",
       "          [ 66.,  49.,  23.],\n",
       "          [ 74.,  52.,  29.],\n",
       "          [ 77.,  53.,  29.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 55.,   0.,   0.],\n",
       "          [ 50.,   0.,   0.],\n",
       "          [ 42.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 45.,  22.,   8.],\n",
       "          [ 53.,  30.,  14.],\n",
       "          [ 47.,  21.,   4.]],\n",
       "\n",
       "         [[ 56.,   0.,   1.],\n",
       "          [ 49.,   1.,   1.],\n",
       "          [ 42.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 54.,  30.,  18.],\n",
       "          [ 62.,  39.,  23.],\n",
       "          [ 52.,  29.,  11.]],\n",
       "\n",
       "         [[ 55.,   0.,   5.],\n",
       "          [ 44.,   0.,   1.],\n",
       "          [ 41.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 53.,  31.,  17.],\n",
       "          [ 57.,  35.,  21.],\n",
       "          [ 56.,  34.,  20.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  6.,   1.,  23.],\n",
       "          [  1.,   1.,  53.],\n",
       "          [  0.,   0.,  56.],\n",
       "          ...,\n",
       "          [ 98.,  76.,  53.],\n",
       "          [ 71.,  51.,  27.],\n",
       "          [ 75.,  48.,  27.]],\n",
       "\n",
       "         [[  6.,   0.,  26.],\n",
       "          [  1.,   0.,  68.],\n",
       "          [  0.,   0.,  70.],\n",
       "          ...,\n",
       "          [ 98.,  70.,  48.],\n",
       "          [ 71.,  51.,  27.],\n",
       "          [ 75.,  48.,  27.]],\n",
       "\n",
       "         [[  4.,   1.,  32.],\n",
       "          [  0.,   1.,  70.],\n",
       "          [  0.,   0.,  72.],\n",
       "          ...,\n",
       "          [ 99.,  73.,  50.],\n",
       "          [ 71.,  51.,  27.],\n",
       "          [ 77.,  50.,  29.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 41.,   1.,   2.],\n",
       "          [ 19.,   0.,   6.],\n",
       "          [ 11.,   0.,   8.],\n",
       "          ...,\n",
       "          [ 39.,  20.,   6.],\n",
       "          [ 40.,  18.,   5.],\n",
       "          [ 55.,  28.,  17.]],\n",
       "\n",
       "         [[ 42.,   1.,   0.],\n",
       "          [ 20.,   0.,   2.],\n",
       "          [ 11.,   0.,   8.],\n",
       "          ...,\n",
       "          [ 43.,  24.,  10.],\n",
       "          [ 41.,  19.,   6.],\n",
       "          [ 56.,  29.,  18.]],\n",
       "\n",
       "         [[ 44.,   0.,   1.],\n",
       "          [ 20.,   1.,   7.],\n",
       "          [ 11.,   0.,   6.],\n",
       "          ...,\n",
       "          [ 59.,  37.,  24.],\n",
       "          [ 53.,  31.,  18.],\n",
       "          [ 58.,  36.,  23.]]],\n",
       "\n",
       "\n",
       "        [[[ 55.,   1.,   0.],\n",
       "          [ 52.,   2.,   3.],\n",
       "          [ 47.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 95.,  53.,  29.],\n",
       "          [ 92.,  51.,  29.],\n",
       "          [ 58.,  20.,   7.]],\n",
       "\n",
       "         [[ 55.,   1.,   0.],\n",
       "          [ 53.,   3.,   4.],\n",
       "          [ 47.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 95.,  53.,  29.],\n",
       "          [ 93.,  51.,  29.],\n",
       "          [ 58.,  20.,   7.]],\n",
       "\n",
       "         [[ 54.,   0.,   0.],\n",
       "          [ 53.,   3.,   4.],\n",
       "          [ 48.,   2.,   2.],\n",
       "          ...,\n",
       "          [ 96.,  54.,  30.],\n",
       "          [ 94.,  52.,  30.],\n",
       "          [ 57.,  19.,   6.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 63.,  39.,  27.],\n",
       "          [ 38.,  20.,   8.],\n",
       "          [ 21.,   8.,   0.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 58.,  34.,  22.],\n",
       "          [ 36.,  22.,   9.],\n",
       "          [ 19.,   8.,   4.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 64.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 56.,  34.,  21.],\n",
       "          [ 34.,  20.,   7.],\n",
       "          [ 19.,   8.,   2.]]],\n",
       "\n",
       "\n",
       "        [[[ 99.,   1.,   0.],\n",
       "          [ 98.,   0.,   0.],\n",
       "          [ 85.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 27.,  15.,   3.],\n",
       "          [ 26.,  18.,   5.]],\n",
       "\n",
       "         [[104.,   0.,   1.],\n",
       "          [104.,   0.,   1.],\n",
       "          [ 98.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 27.,  15.,   3.],\n",
       "          [ 26.,  18.,   5.]],\n",
       "\n",
       "         [[ 85.,   4.,   0.],\n",
       "          [ 85.,   4.,   0.],\n",
       "          [ 87.,   3.,   1.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 26.,  14.,   2.],\n",
       "          [ 28.,  20.,   7.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 25.,  11.,   0.],\n",
       "          [ 25.,   7.,   3.],\n",
       "          [ 27.,   9.,   5.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 38.,   4.,   2.],\n",
       "          [ 36.,   5.,   3.],\n",
       "          [ 30.,   4.,   5.],\n",
       "          ...,\n",
       "          [103.,  52.,  31.],\n",
       "          [100.,  54.,  31.],\n",
       "          [101.,  56.,  33.]],\n",
       "\n",
       "         [[ 38.,   4.,   5.],\n",
       "          [ 36.,   4.,   7.],\n",
       "          [ 30.,   4.,   5.],\n",
       "          ...,\n",
       "          [105.,  54.,  35.],\n",
       "          [103.,  56.,  36.],\n",
       "          [108.,  63.,  40.]],\n",
       "\n",
       "         [[ 36.,   1.,   5.],\n",
       "          [ 34.,   1.,   8.],\n",
       "          [ 30.,   4.,   5.],\n",
       "          ...,\n",
       "          [116.,  80.,  58.],\n",
       "          [111.,  80.,  52.],\n",
       "          [114.,  83.,  54.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 58.,   0.,   3.],\n",
       "          ...,\n",
       "          [ 66.,  42.,  30.],\n",
       "          [ 69.,  42.,  31.],\n",
       "          [ 74.,  48.,  35.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 58.,   0.,   3.],\n",
       "          ...,\n",
       "          [ 44.,  20.,   8.],\n",
       "          [ 47.,  20.,   9.],\n",
       "          [ 72.,  49.,  35.]],\n",
       "\n",
       "         [[ 61.,   0.,   0.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          [ 55.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 47.,  18.,  10.],\n",
       "          [ 47.,  23.,  11.],\n",
       "          [ 60.,  37.,  23.]]],\n",
       "\n",
       "\n",
       "        [[[ 26.,   1.,   7.],\n",
       "          [ 19.,   2.,  12.],\n",
       "          [ 11.,   1.,  10.],\n",
       "          ...,\n",
       "          [124.,  89.,  67.],\n",
       "          [109.,  87.,  63.],\n",
       "          [102.,  82.,  55.]],\n",
       "\n",
       "         [[ 26.,   1.,   5.],\n",
       "          [ 18.,   1.,   9.],\n",
       "          [ 11.,   1.,   9.],\n",
       "          ...,\n",
       "          [ 68.,  52.,  27.],\n",
       "          [ 70.,  53.,  27.],\n",
       "          [ 76.,  56.,  31.]],\n",
       "\n",
       "         [[ 25.,   0.,   3.],\n",
       "          [ 17.,   0.,   6.],\n",
       "          [ 11.,   0.,  19.],\n",
       "          ...,\n",
       "          [ 66.,  49.,  23.],\n",
       "          [ 74.,  52.,  29.],\n",
       "          [ 77.,  53.,  29.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 55.,   0.,   0.],\n",
       "          [ 50.,   0.,   0.],\n",
       "          [ 42.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 45.,  22.,   8.],\n",
       "          [ 53.,  30.,  14.],\n",
       "          [ 47.,  21.,   4.]],\n",
       "\n",
       "         [[ 56.,   0.,   1.],\n",
       "          [ 49.,   1.,   1.],\n",
       "          [ 42.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 54.,  30.,  18.],\n",
       "          [ 62.,  39.,  23.],\n",
       "          [ 52.,  29.,  11.]],\n",
       "\n",
       "         [[ 55.,   0.,   5.],\n",
       "          [ 44.,   0.,   1.],\n",
       "          [ 41.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 53.,  31.,  17.],\n",
       "          [ 57.,  35.,  21.],\n",
       "          [ 56.,  34.,  20.]]],\n",
       "\n",
       "\n",
       "        [[[ 98.,   0.,   1.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          [ 87.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 26.,  18.,   7.]],\n",
       "\n",
       "         [[100.,   0.,   2.],\n",
       "          [100.,   2.,   3.],\n",
       "          [ 99.,   1.,   2.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 26.,  18.,   7.]],\n",
       "\n",
       "         [[ 85.,   1.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          [ 87.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 28.,  20.,   9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 29.,   8.,   3.],\n",
       "          [ 29.,   8.,   3.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 55.,   1.,   0.],\n",
       "          [ 52.,   2.,   3.],\n",
       "          [ 47.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 95.,  53.,  29.],\n",
       "          [ 92.,  51.,  29.],\n",
       "          [ 58.,  20.,   7.]],\n",
       "\n",
       "         [[ 55.,   1.,   0.],\n",
       "          [ 53.,   3.,   4.],\n",
       "          [ 47.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 95.,  53.,  29.],\n",
       "          [ 93.,  51.,  29.],\n",
       "          [ 58.,  20.,   7.]],\n",
       "\n",
       "         [[ 54.,   0.,   0.],\n",
       "          [ 53.,   3.,   4.],\n",
       "          [ 48.,   2.,   2.],\n",
       "          ...,\n",
       "          [ 96.,  54.,  30.],\n",
       "          [ 94.,  52.,  30.],\n",
       "          [ 57.,  19.,   6.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 63.,  39.,  27.],\n",
       "          [ 38.,  20.,   8.],\n",
       "          [ 21.,   8.,   0.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 58.,  34.,  22.],\n",
       "          [ 36.,  22.,   9.],\n",
       "          [ 19.,   8.,   4.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 64.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 56.,  34.,  21.],\n",
       "          [ 34.,  20.,   7.],\n",
       "          [ 19.,   8.,   2.]]],\n",
       "\n",
       "\n",
       "        [[[ 99.,   1.,   0.],\n",
       "          [ 98.,   0.,   0.],\n",
       "          [ 85.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 27.,  15.,   3.],\n",
       "          [ 26.,  18.,   5.]],\n",
       "\n",
       "         [[104.,   0.,   1.],\n",
       "          [104.,   0.,   1.],\n",
       "          [ 98.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 27.,  15.,   3.],\n",
       "          [ 26.,  18.,   5.]],\n",
       "\n",
       "         [[ 85.,   4.,   0.],\n",
       "          [ 85.,   4.,   0.],\n",
       "          [ 87.,   3.,   1.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 26.,  14.,   2.],\n",
       "          [ 28.,  20.,   7.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 25.,  11.,   0.],\n",
       "          [ 25.,   7.,   3.],\n",
       "          [ 27.,   9.,   5.]]],\n",
       "\n",
       "\n",
       "        [[[ 65.,   1.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 89.,  49.,  24.],\n",
       "          [ 39.,  11.,   0.],\n",
       "          [ 19.,   8.,   2.]],\n",
       "\n",
       "         [[ 66.,   0.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          [ 52.,   2.,   3.],\n",
       "          ...,\n",
       "          [ 90.,  50.,  25.],\n",
       "          [ 39.,   9.,   0.],\n",
       "          [ 21.,   8.,   2.]],\n",
       "\n",
       "         [[ 66.,   0.,   1.],\n",
       "          [ 56.,   0.,   0.],\n",
       "          [ 51.,   1.,   2.],\n",
       "          ...,\n",
       "          [ 92.,  52.,  27.],\n",
       "          [ 38.,  10.,   0.],\n",
       "          [ 20.,   9.,   3.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   3.],\n",
       "          [ 20.,   5.,   0.],\n",
       "          [ 25.,  11.,   2.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 29.,  15.,   4.],\n",
       "          [ 22.,   9.,   1.],\n",
       "          [ 25.,  12.,   4.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 25.,  12.,   3.],\n",
       "          [ 23.,   9.,   0.],\n",
       "          [ 25.,  11.,   2.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 26.,   1.,   7.],\n",
       "          [ 19.,   2.,  12.],\n",
       "          [ 11.,   1.,  10.],\n",
       "          ...,\n",
       "          [124.,  89.,  67.],\n",
       "          [109.,  87.,  63.],\n",
       "          [102.,  82.,  55.]],\n",
       "\n",
       "         [[ 26.,   1.,   5.],\n",
       "          [ 18.,   1.,   9.],\n",
       "          [ 11.,   1.,   9.],\n",
       "          ...,\n",
       "          [ 68.,  52.,  27.],\n",
       "          [ 70.,  53.,  27.],\n",
       "          [ 76.,  56.,  31.]],\n",
       "\n",
       "         [[ 25.,   0.,   3.],\n",
       "          [ 17.,   0.,   6.],\n",
       "          [ 11.,   0.,  19.],\n",
       "          ...,\n",
       "          [ 66.,  49.,  23.],\n",
       "          [ 74.,  52.,  29.],\n",
       "          [ 77.,  53.,  29.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 55.,   0.,   0.],\n",
       "          [ 50.,   0.,   0.],\n",
       "          [ 42.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 45.,  22.,   8.],\n",
       "          [ 53.,  30.,  14.],\n",
       "          [ 47.,  21.,   4.]],\n",
       "\n",
       "         [[ 56.,   0.,   1.],\n",
       "          [ 49.,   1.,   1.],\n",
       "          [ 42.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 54.,  30.,  18.],\n",
       "          [ 62.,  39.,  23.],\n",
       "          [ 52.,  29.,  11.]],\n",
       "\n",
       "         [[ 55.,   0.,   5.],\n",
       "          [ 44.,   0.,   1.],\n",
       "          [ 41.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 53.,  31.,  17.],\n",
       "          [ 57.,  35.,  21.],\n",
       "          [ 56.,  34.,  20.]]],\n",
       "\n",
       "\n",
       "        [[[ 98.,   0.,   1.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          [ 87.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 26.,  18.,   7.]],\n",
       "\n",
       "         [[100.,   0.,   2.],\n",
       "          [100.,   2.,   3.],\n",
       "          [ 99.,   1.,   2.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 26.,  18.,   7.]],\n",
       "\n",
       "         [[ 85.,   1.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          [ 87.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 28.,  20.,   9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 29.,   8.,   3.],\n",
       "          [ 29.,   8.,   3.]]],\n",
       "\n",
       "\n",
       "        [[[ 68.,   3.,   1.],\n",
       "          [ 59.,   1.,   0.],\n",
       "          [ 52.,   4.,   2.],\n",
       "          ...,\n",
       "          [ 85.,  49.,  25.],\n",
       "          [ 29.,  12.,   2.],\n",
       "          [ 28.,  15.,   9.]],\n",
       "\n",
       "         [[ 68.,   3.,   1.],\n",
       "          [ 59.,   1.,   0.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 85.,  49.,  25.],\n",
       "          [ 29.,  12.,   2.],\n",
       "          [ 29.,  16.,  10.]],\n",
       "\n",
       "         [[ 68.,   3.,   1.],\n",
       "          [ 59.,   1.,   0.],\n",
       "          [ 53.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 86.,  48.,  27.],\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 28.,  15.,   9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  13.,   4.],\n",
       "          [ 22.,   7.,   2.],\n",
       "          [ 29.,  12.,   4.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  13.,   5.],\n",
       "          [ 20.,   6.,   3.],\n",
       "          [ 30.,  11.,   4.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 22.,  12.,   3.],\n",
       "          [ 25.,  12.,   6.],\n",
       "          [ 27.,  12.,   5.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 99.,   1.,   0.],\n",
       "          [ 98.,   0.,   0.],\n",
       "          [ 85.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 27.,  15.,   3.],\n",
       "          [ 26.,  18.,   5.]],\n",
       "\n",
       "         [[104.,   0.,   1.],\n",
       "          [104.,   0.,   1.],\n",
       "          [ 98.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 27.,  15.,   3.],\n",
       "          [ 26.,  18.,   5.]],\n",
       "\n",
       "         [[ 85.,   4.,   0.],\n",
       "          [ 85.,   4.,   0.],\n",
       "          [ 87.,   3.,   1.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   1.],\n",
       "          [ 26.,  14.,   2.],\n",
       "          [ 28.,  20.,   7.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   0.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 25.,  11.,   0.],\n",
       "          [ 25.,   7.,   3.],\n",
       "          [ 27.,   9.,   5.]]],\n",
       "\n",
       "\n",
       "        [[[ 65.,   1.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 89.,  49.,  24.],\n",
       "          [ 39.,  11.,   0.],\n",
       "          [ 19.,   8.,   2.]],\n",
       "\n",
       "         [[ 66.,   0.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          [ 52.,   2.,   3.],\n",
       "          ...,\n",
       "          [ 90.,  50.,  25.],\n",
       "          [ 39.,   9.,   0.],\n",
       "          [ 21.,   8.,   2.]],\n",
       "\n",
       "         [[ 66.,   0.,   1.],\n",
       "          [ 56.,   0.,   0.],\n",
       "          [ 51.,   1.,   2.],\n",
       "          ...,\n",
       "          [ 92.,  52.,  27.],\n",
       "          [ 38.,  10.,   0.],\n",
       "          [ 20.,   9.,   3.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   3.],\n",
       "          [ 20.,   5.,   0.],\n",
       "          [ 25.,  11.,   2.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 29.,  15.,   4.],\n",
       "          [ 22.,   9.,   1.],\n",
       "          [ 25.,  12.,   4.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 25.,  12.,   3.],\n",
       "          [ 23.,   9.,   0.],\n",
       "          [ 25.,  11.,   2.]]],\n",
       "\n",
       "\n",
       "        [[[ 96.,   0.,   1.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          [ 90.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 28.,  22.,  10.]],\n",
       "\n",
       "         [[104.,   1.,   2.],\n",
       "          [104.,   1.,   2.],\n",
       "          [100.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 28.,  22.,  10.]],\n",
       "\n",
       "         [[ 91.,   3.,   1.],\n",
       "          [ 91.,   3.,   1.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  23.,  11.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[  5.,   2.,  19.],\n",
       "          [  2.,   0.,  57.],\n",
       "          [  1.,   0.,  57.],\n",
       "          ...,\n",
       "          [100.,  76.,  52.],\n",
       "          [ 71.,  51.,  27.],\n",
       "          [ 75.,  48.,  27.]],\n",
       "\n",
       "         [[  5.,   3.,  27.],\n",
       "          [  1.,   0.,  70.],\n",
       "          [  0.,   0.,  67.],\n",
       "          ...,\n",
       "          [ 97.,  71.,  48.],\n",
       "          [ 71.,  51.,  27.],\n",
       "          [ 75.,  48.,  27.]],\n",
       "\n",
       "         [[  4.,   1.,  30.],\n",
       "          [  1.,   0.,  70.],\n",
       "          [  1.,   0.,  78.],\n",
       "          ...,\n",
       "          [ 98.,  70.,  48.],\n",
       "          [ 71.,  51.,  27.],\n",
       "          [ 77.,  50.,  29.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 41.,   1.,   2.],\n",
       "          [ 19.,   0.,   6.],\n",
       "          [ 11.,   0.,   8.],\n",
       "          ...,\n",
       "          [ 39.,  20.,   6.],\n",
       "          [ 40.,  18.,   5.],\n",
       "          [ 55.,  28.,  17.]],\n",
       "\n",
       "         [[ 42.,   1.,   0.],\n",
       "          [ 20.,   0.,   2.],\n",
       "          [ 11.,   0.,   8.],\n",
       "          ...,\n",
       "          [ 43.,  24.,  10.],\n",
       "          [ 41.,  19.,   6.],\n",
       "          [ 56.,  29.,  18.]],\n",
       "\n",
       "         [[ 44.,   0.,   1.],\n",
       "          [ 20.,   1.,   7.],\n",
       "          [ 11.,   0.,   6.],\n",
       "          ...,\n",
       "          [ 59.,  37.,  24.],\n",
       "          [ 53.,  31.,  18.],\n",
       "          [ 58.,  36.,  23.]]],\n",
       "\n",
       "\n",
       "        [[[ 62.,   1.,   0.],\n",
       "          [ 56.,   0.,   1.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 87.,  47.,  22.],\n",
       "          [ 33.,  10.,   2.],\n",
       "          [ 22.,  11.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 56.,   0.,   1.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 88.,  48.,  23.],\n",
       "          [ 33.,  10.,   2.],\n",
       "          [ 22.,  11.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 55.,   0.,   0.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 91.,  50.,  28.],\n",
       "          [ 31.,   8.,   2.],\n",
       "          [ 22.,  11.,   5.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  13.,   2.],\n",
       "          [ 20.,   5.,   0.],\n",
       "          [ 25.,  11.,   2.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 26.,  13.,   4.],\n",
       "          [ 22.,   9.,   1.],\n",
       "          [ 25.,  12.,   4.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 22.,  12.,   2.],\n",
       "          [ 22.,   9.,   1.],\n",
       "          [ 25.,  12.,   4.]]],\n",
       "\n",
       "\n",
       "        [[[ 52.,   2.,   1.],\n",
       "          [ 36.,   0.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 94.,  52.,  28.],\n",
       "          [ 93.,  51.,  27.],\n",
       "          [ 93.,  48.,  25.]],\n",
       "\n",
       "         [[ 52.,   2.,   1.],\n",
       "          [ 37.,   2.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 94.,  54.,  29.],\n",
       "          [ 93.,  51.,  27.],\n",
       "          [ 92.,  52.,  27.]],\n",
       "\n",
       "         [[ 52.,   2.,   1.],\n",
       "          [ 39.,   1.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [100.,  58.,  34.],\n",
       "          [ 98.,  53.,  30.],\n",
       "          [ 96.,  54.,  30.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 57.,  31.,  16.],\n",
       "          [ 74.,  51.,  37.],\n",
       "          [ 72.,  49.,  35.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 48.,  22.,   9.],\n",
       "          [ 73.,  51.,  37.],\n",
       "          [ 51.,  29.,  15.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 48.,  22.,   7.],\n",
       "          [ 74.,  51.,  33.],\n",
       "          [ 47.,  28.,  13.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 68.,   3.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 53.,   3.,   2.],\n",
       "          ...,\n",
       "          [ 83.,  48.,  26.],\n",
       "          [ 27.,  14.,   5.],\n",
       "          [ 29.,  14.,   9.]],\n",
       "\n",
       "         [[ 68.,   3.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 53.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 85.,  49.,  27.],\n",
       "          [ 26.,  12.,   3.],\n",
       "          [ 30.,  15.,  10.]],\n",
       "\n",
       "         [[ 68.,   3.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 52.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 86.,  49.,  30.],\n",
       "          [ 26.,  11.,   4.],\n",
       "          [ 30.,  15.,  10.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 25.,  12.,   6.],\n",
       "          [ 28.,  11.,   4.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 26.,  12.,   9.],\n",
       "          [ 28.,  11.,   4.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 24.,  11.,   5.],\n",
       "          [ 25.,  12.,   6.],\n",
       "          [ 27.,  12.,   5.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,  74.],\n",
       "          [  0.,   0.,  80.],\n",
       "          [  0.,   0.,  83.],\n",
       "          ...,\n",
       "          [111.,  35.,  22.],\n",
       "          [100.,  48.,  34.],\n",
       "          [ 80.,  56.,  32.]],\n",
       "\n",
       "         [[  4.,   1.,  56.],\n",
       "          [  2.,   1.,  59.],\n",
       "          [  2.,   2.,  66.],\n",
       "          ...,\n",
       "          [108.,  36.,  22.],\n",
       "          [100.,  48.,  34.],\n",
       "          [ 80.,  56.,  32.]],\n",
       "\n",
       "         [[ 11.,   6.,  12.],\n",
       "          [  8.,   3.,   7.],\n",
       "          [  6.,   5.,  10.],\n",
       "          ...,\n",
       "          [106.,  40.,  24.],\n",
       "          [103.,  51.,  37.],\n",
       "          [ 78.,  54.,  30.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  9.,   2.,   9.],\n",
       "          [ 13.,   0.,   9.],\n",
       "          [ 12.,   0.,  12.],\n",
       "          ...,\n",
       "          [ 39.,  19.,   8.],\n",
       "          [ 41.,  18.,  10.],\n",
       "          [ 42.,  19.,  11.]],\n",
       "\n",
       "         [[ 11.,   2.,   7.],\n",
       "          [ 15.,   0.,   7.],\n",
       "          [ 12.,   0.,  12.],\n",
       "          ...,\n",
       "          [ 39.,  19.,   8.],\n",
       "          [ 41.,  18.,  10.],\n",
       "          [ 42.,  19.,  11.]],\n",
       "\n",
       "         [[ 10.,   0.,   9.],\n",
       "          [ 10.,   0.,   9.],\n",
       "          [ 12.,   0.,  12.],\n",
       "          ...,\n",
       "          [ 43.,  19.,   7.],\n",
       "          [ 45.,  23.,  10.],\n",
       "          [ 43.,  21.,   8.]]],\n",
       "\n",
       "\n",
       "        [[[ 96.,   0.,   1.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          [ 90.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  21.,  10.]],\n",
       "\n",
       "         [[105.,   1.,   2.],\n",
       "          [104.,   1.,   2.],\n",
       "          [100.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  21.,  10.]],\n",
       "\n",
       "         [[ 88.,   5.,   0.],\n",
       "          [ 89.,   4.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  15.,   6.],\n",
       "          [ 30.,  22.,  11.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  10.,   6.],\n",
       "          [ 29.,  11.,   7.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 62.,   1.,   0.],\n",
       "          [ 56.,   0.,   1.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 87.,  47.,  22.],\n",
       "          [ 33.,  10.,   2.],\n",
       "          [ 22.,  11.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 56.,   0.,   1.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 88.,  48.,  23.],\n",
       "          [ 33.,  10.,   2.],\n",
       "          [ 22.,  11.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 55.,   0.,   0.],\n",
       "          [ 52.,   2.,   1.],\n",
       "          ...,\n",
       "          [ 91.,  50.,  28.],\n",
       "          [ 31.,   8.,   2.],\n",
       "          [ 22.,  11.,   5.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  13.,   2.],\n",
       "          [ 20.,   5.,   0.],\n",
       "          [ 25.,  11.,   2.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 26.,  13.,   4.],\n",
       "          [ 22.,   9.,   1.],\n",
       "          [ 25.,  12.,   4.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 22.,  12.,   2.],\n",
       "          [ 22.,   9.,   1.],\n",
       "          [ 25.,  12.,   4.]]],\n",
       "\n",
       "\n",
       "        [[[ 52.,   2.,   1.],\n",
       "          [ 36.,   0.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 94.,  52.,  28.],\n",
       "          [ 93.,  51.,  27.],\n",
       "          [ 93.,  48.,  25.]],\n",
       "\n",
       "         [[ 52.,   2.,   1.],\n",
       "          [ 37.,   2.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 94.,  54.,  29.],\n",
       "          [ 93.,  51.,  27.],\n",
       "          [ 92.,  52.,  27.]],\n",
       "\n",
       "         [[ 52.,   2.,   1.],\n",
       "          [ 39.,   1.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [100.,  58.,  34.],\n",
       "          [ 98.,  53.,  30.],\n",
       "          [ 96.,  54.,  30.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 57.,  31.,  16.],\n",
       "          [ 74.,  51.,  37.],\n",
       "          [ 72.,  49.,  35.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 48.,  22.,   9.],\n",
       "          [ 73.,  51.,  37.],\n",
       "          [ 51.,  29.,  15.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 48.,  22.,   7.],\n",
       "          [ 74.,  51.,  33.],\n",
       "          [ 47.,  28.,  13.]]],\n",
       "\n",
       "\n",
       "        [[[ 94.,   0.,   0.],\n",
       "          [ 93.,   2.,   1.],\n",
       "          [ 86.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 27.,  17.,   7.]],\n",
       "\n",
       "         [[103.,   0.,   3.],\n",
       "          [101.,   1.,   3.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 27.,  17.,   7.]],\n",
       "\n",
       "         [[ 86.,   2.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          [ 87.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  19.,   9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 25.,  11.,   0.],\n",
       "          [ 25.,   8.,   1.],\n",
       "          [ 25.,   8.,   1.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,  74.],\n",
       "          [  0.,   0.,  80.],\n",
       "          [  0.,   0.,  83.],\n",
       "          ...,\n",
       "          [111.,  35.,  22.],\n",
       "          [100.,  48.,  34.],\n",
       "          [ 80.,  56.,  32.]],\n",
       "\n",
       "         [[  4.,   1.,  56.],\n",
       "          [  2.,   1.,  59.],\n",
       "          [  2.,   2.,  66.],\n",
       "          ...,\n",
       "          [108.,  36.,  22.],\n",
       "          [100.,  48.,  34.],\n",
       "          [ 80.,  56.,  32.]],\n",
       "\n",
       "         [[ 11.,   6.,  12.],\n",
       "          [  8.,   3.,   7.],\n",
       "          [  6.,   5.,  10.],\n",
       "          ...,\n",
       "          [106.,  40.,  24.],\n",
       "          [103.,  51.,  37.],\n",
       "          [ 78.,  54.,  30.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  9.,   2.,   9.],\n",
       "          [ 13.,   0.,   9.],\n",
       "          [ 12.,   0.,  12.],\n",
       "          ...,\n",
       "          [ 39.,  19.,   8.],\n",
       "          [ 41.,  18.,  10.],\n",
       "          [ 42.,  19.,  11.]],\n",
       "\n",
       "         [[ 11.,   2.,   7.],\n",
       "          [ 15.,   0.,   7.],\n",
       "          [ 12.,   0.,  12.],\n",
       "          ...,\n",
       "          [ 39.,  19.,   8.],\n",
       "          [ 41.,  18.,  10.],\n",
       "          [ 42.,  19.,  11.]],\n",
       "\n",
       "         [[ 10.,   0.,   9.],\n",
       "          [ 10.,   0.,   9.],\n",
       "          [ 12.,   0.,  12.],\n",
       "          ...,\n",
       "          [ 43.,  19.,   7.],\n",
       "          [ 45.,  23.,  10.],\n",
       "          [ 43.,  21.,   8.]]],\n",
       "\n",
       "\n",
       "        [[[ 96.,   0.,   1.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          [ 90.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  21.,  10.]],\n",
       "\n",
       "         [[105.,   1.,   2.],\n",
       "          [104.,   1.,   2.],\n",
       "          [100.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  21.,  10.]],\n",
       "\n",
       "         [[ 88.,   5.,   0.],\n",
       "          [ 89.,   4.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  15.,   6.],\n",
       "          [ 30.,  22.,  11.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  10.,   6.],\n",
       "          [ 29.,  11.,   7.]]],\n",
       "\n",
       "\n",
       "        [[[ 47.,   3.,   2.],\n",
       "          [ 33.,   4.,   0.],\n",
       "          [ 30.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 98.,  50.,  28.],\n",
       "          [100.,  55.,  32.],\n",
       "          [ 98.,  53.,  30.]],\n",
       "\n",
       "         [[ 44.,   3.,   1.],\n",
       "          [ 33.,   4.,   0.],\n",
       "          [ 31.,   3.,   0.],\n",
       "          ...,\n",
       "          [ 98.,  53.,  30.],\n",
       "          [101.,  56.,  33.],\n",
       "          [ 98.,  53.,  30.]],\n",
       "\n",
       "         [[ 46.,   0.,   0.],\n",
       "          [ 35.,   1.,   0.],\n",
       "          [ 33.,   3.,   1.],\n",
       "          ...,\n",
       "          [ 99.,  54.,  31.],\n",
       "          [109.,  64.,  41.],\n",
       "          [105.,  60.,  37.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 52.,  28.,  16.],\n",
       "          [ 71.,  44.,  33.],\n",
       "          [ 75.,  47.,  35.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 44.,  20.,   8.],\n",
       "          [ 55.,  33.,  22.],\n",
       "          [ 77.,  55.,  41.]],\n",
       "\n",
       "         [[ 64.,   0.,   1.],\n",
       "          [ 59.,   0.,   0.],\n",
       "          [ 60.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 46.,  19.,   8.],\n",
       "          [ 50.,  23.,  12.],\n",
       "          [ 79.,  51.,  39.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 52.,   2.,   1.],\n",
       "          [ 36.,   0.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 94.,  52.,  28.],\n",
       "          [ 93.,  51.,  27.],\n",
       "          [ 93.,  48.,  25.]],\n",
       "\n",
       "         [[ 52.,   2.,   1.],\n",
       "          [ 37.,   2.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 94.,  54.,  29.],\n",
       "          [ 93.,  51.,  27.],\n",
       "          [ 92.,  52.,  27.]],\n",
       "\n",
       "         [[ 52.,   2.,   1.],\n",
       "          [ 39.,   1.,   0.],\n",
       "          [ 32.,   1.,   0.],\n",
       "          ...,\n",
       "          [100.,  58.,  34.],\n",
       "          [ 98.,  53.,  30.],\n",
       "          [ 96.,  54.,  30.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 57.,  31.,  16.],\n",
       "          [ 74.,  51.,  37.],\n",
       "          [ 72.,  49.,  35.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 48.,  22.,   9.],\n",
       "          [ 73.,  51.,  37.],\n",
       "          [ 51.,  29.,  15.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 48.,  22.,   7.],\n",
       "          [ 74.,  51.,  33.],\n",
       "          [ 47.,  28.,  13.]]],\n",
       "\n",
       "\n",
       "        [[[ 94.,   0.,   0.],\n",
       "          [ 93.,   2.,   1.],\n",
       "          [ 86.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 27.,  17.,   7.]],\n",
       "\n",
       "         [[103.,   0.,   3.],\n",
       "          [101.,   1.,   3.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 27.,  17.,   7.]],\n",
       "\n",
       "         [[ 86.,   2.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          [ 87.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  19.,   9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 27.,  10.,   3.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 25.,  11.,   0.],\n",
       "          [ 25.,   8.,   1.],\n",
       "          [ 25.,   8.,   1.]]],\n",
       "\n",
       "\n",
       "        [[[ 72.,   0.,   1.],\n",
       "          [ 66.,   0.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 23.,   9.,   0.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 28.,  11.,   4.]],\n",
       "\n",
       "         [[ 72.,   0.,   1.],\n",
       "          [ 66.,   0.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 22.,   9.,   0.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 28.,  11.,   4.]],\n",
       "\n",
       "         [[ 70.,   0.,   0.],\n",
       "          [ 66.,   0.,   1.],\n",
       "          [ 58.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 19.,  11.,   0.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 22.,   9.,   3.],\n",
       "          [ 26.,  11.,   4.],\n",
       "          [ 26.,  11.,   4.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 22.,   9.,   3.],\n",
       "          [ 26.,  11.,   4.],\n",
       "          [ 26.,  11.,   4.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 60.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 23.,  10.,   1.],\n",
       "          [ 27.,  10.,   3.],\n",
       "          [ 25.,   8.,   1.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 96.,   0.,   1.],\n",
       "          [ 96.,   0.,   1.],\n",
       "          [ 90.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  21.,  10.]],\n",
       "\n",
       "         [[105.,   1.,   2.],\n",
       "          [104.,   1.,   2.],\n",
       "          [100.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 30.,  16.,   7.],\n",
       "          [ 29.,  21.,  10.]],\n",
       "\n",
       "         [[ 88.,   5.,   0.],\n",
       "          [ 89.,   4.,   0.],\n",
       "          [ 86.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 28.,  14.,   5.],\n",
       "          [ 29.,  15.,   6.],\n",
       "          [ 30.,  22.,  11.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 29.,  12.,   4.],\n",
       "          [ 29.,  12.,   5.],\n",
       "          [ 29.,  12.,   5.]],\n",
       "\n",
       "         [[ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 28.,  11.,   3.],\n",
       "          [ 28.,  10.,   6.],\n",
       "          [ 29.,  11.,   7.]]],\n",
       "\n",
       "\n",
       "        [[[ 47.,   3.,   2.],\n",
       "          [ 33.,   4.,   0.],\n",
       "          [ 30.,   2.,   0.],\n",
       "          ...,\n",
       "          [ 98.,  50.,  28.],\n",
       "          [100.,  55.,  32.],\n",
       "          [ 98.,  53.,  30.]],\n",
       "\n",
       "         [[ 44.,   3.,   1.],\n",
       "          [ 33.,   4.,   0.],\n",
       "          [ 31.,   3.,   0.],\n",
       "          ...,\n",
       "          [ 98.,  53.,  30.],\n",
       "          [101.,  56.,  33.],\n",
       "          [ 98.,  53.,  30.]],\n",
       "\n",
       "         [[ 46.,   0.,   0.],\n",
       "          [ 35.,   1.,   0.],\n",
       "          [ 33.,   3.,   1.],\n",
       "          ...,\n",
       "          [ 99.,  54.,  31.],\n",
       "          [109.,  64.,  41.],\n",
       "          [105.,  60.,  37.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 62.,   0.,   1.],\n",
       "          ...,\n",
       "          [ 52.,  28.,  16.],\n",
       "          [ 71.,  44.,  33.],\n",
       "          [ 75.,  47.,  35.]],\n",
       "\n",
       "         [[ 64.,   0.,   0.],\n",
       "          [ 64.,   0.,   0.],\n",
       "          [ 61.,   0.,   0.],\n",
       "          ...,\n",
       "          [ 44.,  20.,   8.],\n",
       "          [ 55.,  33.,  22.],\n",
       "          [ 77.,  55.,  41.]],\n",
       "\n",
       "         [[ 64.,   0.,   1.],\n",
       "          [ 59.,   0.,   0.],\n",
       "          [ 60.,   0.,   2.],\n",
       "          ...,\n",
       "          [ 46.,  19.,   8.],\n",
       "          [ 50.,  23.,  12.],\n",
       "          [ 79.,  51.,  39.]]],\n",
       "\n",
       "\n",
       "        [[[ 32.,   0.,   1.],\n",
       "          [ 30.,   2.,   1.],\n",
       "          [ 24.,   1.,   9.],\n",
       "          ...,\n",
       "          [100.,  53.,  27.],\n",
       "          [100.,  53.,  27.],\n",
       "          [ 98.,  57.,  29.]],\n",
       "\n",
       "         [[ 32.,   0.,   1.],\n",
       "          [ 30.,   2.,   1.],\n",
       "          [ 24.,   2.,   4.],\n",
       "          ...,\n",
       "          [107.,  70.,  44.],\n",
       "          [110.,  70.,  45.],\n",
       "          [113.,  76.,  50.]],\n",
       "\n",
       "         [[ 32.,   0.,   1.],\n",
       "          [ 30.,   2.,   1.],\n",
       "          [ 22.,   1.,   0.],\n",
       "          ...,\n",
       "          [104.,  78.,  53.],\n",
       "          [103.,  75.,  51.],\n",
       "          [114.,  84.,  60.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 56.,   0.,   1.],\n",
       "          [ 55.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 72.,  44.,  33.],\n",
       "          [ 66.,  40.,  27.],\n",
       "          [ 69.,  43.,  30.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 56.,   0.,   1.],\n",
       "          [ 55.,   1.,   1.],\n",
       "          ...,\n",
       "          [ 55.,  27.,  16.],\n",
       "          [ 53.,  30.,  16.],\n",
       "          [ 61.,  38.,  24.]],\n",
       "\n",
       "         [[ 60.,   0.,   0.],\n",
       "          [ 54.,   0.,   0.],\n",
       "          [ 52.,   1.,   0.],\n",
       "          ...,\n",
       "          [ 41.,  20.,   3.],\n",
       "          [ 44.,  18.,   5.],\n",
       "          [ 51.,  25.,  12.]]]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "888b77cd-0a5e-4a64-8093-a323dc0c7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust y_train and y_test for the LSTM sequences\n",
    "y_train_lstm = y_train[sequence_length - 1:]  # Match the sequence length\n",
    "y_test_lstm = y_test[sequence_length - 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a0d3e-cae5-4277-9854-adf346b77a41",
   "metadata": {},
   "source": [
    "### Final evalution of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1eceec2-6019-494c-8e1f-0924b76f67fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0447\n",
      "CNN Loss: 0.045405853539705276, Accuracy: 1.0\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 428ms/step - accuracy: 0.4727 - loss: 0.7172\n",
      "LSTM Loss: 0.706834614276886, Accuracy: 0.5027933120727539\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "as_list() is not defined on an unknown TensorShape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## capsule Network Evaluation\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m capsule_loss, capsule_accuracy \u001b[38;5;241m=\u001b[39m capsule_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapsule Network Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcapsule_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcapsule_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## classification Report and Confusion Matrix\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Drag Software\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Program Files\\Drag Software\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "## CNN Evaluation\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f\"CNN Loss: {cnn_loss}, Accuracy: {cnn_accuracy}\")\n",
    "\n",
    "## LSTM Evaluation\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test_lstm)\n",
    "print(f\"LSTM Loss: {lstm_loss}, Accuracy: {lstm_accuracy}\")\n",
    "\n",
    "## capsule Network Evaluation\n",
    "capsule_loss, capsule_accuracy = capsule_model.evaluate(X_test, y_test)\n",
    "print(f\"Capsule Network Loss: {capsule_loss}, Accuracy: {capsule_accuracy}\")\n",
    "\n",
    "## classification Report and Confusion Matrix\n",
    "y_pred_cnn = (cnn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_pred_lstm = (lstm_model.predict(X_test_lstm) > 0.5).astype(\"int32\")\n",
    "y_pred_capsule = (capsule_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"CNN Classification Report:\\n\", classification_report(y_test, y_pred_cnn))\n",
    "print(\"CNN Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_cnn))\n",
    "\n",
    "print(\"LSTM Classification Report:\\n\", classification_report(y_test_lstm, y_pred_lstm))\n",
    "print(\"LSTM Confusion Matrix:\\n\", confusion_matrix(y_test_lstm, y_pred_lstm))\n",
    "\n",
    "print(\"Capsule Network Classification Report:\\n\", classification_report(y_test, y_pred_capsule))\n",
    "print(\"Capsule Network Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_capsule))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997aecc-b1ef-4c34-84c4-f88fd8d79841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78752936-3c99-4415-8597-1b0ca8696dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cdcae-702c-4f85-9770-a302e3a39b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36595c4f-204b-4375-88ec-e4a9415675ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08d428-706b-4e85-bbe6-27b1a498cfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bf726-4d66-4c09-8992-e7066801380f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2438ef9-6b54-4c22-98ed-8e64a49e5205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e77a7c-19d6-4058-986f-5cf5c141734e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ce89e-5d23-41cc-86e5-1433662fb5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c7c08-41f0-4e41-8eba-fb09ac085b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f1db3-a1e4-43b8-84dd-c8cabf9fec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41a0fe-650e-4e7c-8341-c1755316131f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42b138-5538-4504-a97e-b173101b9d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e59e2-1298-489a-8dc1-ce4826b4d10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efbfde-91c8-456a-a769-272ab2042b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2108448-a60f-40d9-a4f4-b0d8cbbd9b27",
   "metadata": {},
   "source": [
    "### Audio- Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c117f-d664-474f-97c7-afc797e88964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398c855-3ce0-4684-9811-1bc7560bad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, frame_rate=1):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        if count % frame_rate == 0:\n",
    "            cv2.imwrite(os.path.join(output_folder, f\"frame_{count:04d}.jpg\"), frame)\n",
    "        success, frame = cap.read()\n",
    "        count += 1\n",
    "    cap.release()\n",
    "\n",
    "# Example usage\n",
    "extract_frames(r\"C:\\Users\\101ri\\OneDrive\\Desktop\\deep fake detector\\Notebook\\Celeb-real\\id0_0000.mp4\", \"video_frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f331e-c38f-43b2-92fe-1fa775bf01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d689592-3140-46db-a249-40b0339dd02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a113fbf-ac4e-4447-8538-fd65d30faaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_audio(video_path, output_audio_path):\n",
    "    os.system(f\"ffmpeg -i {video_path} -q:a 0 -map a {output_audio_path}\")\n",
    "\n",
    "def audio_to_melspectrogram(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    return log_S, sr\n",
    "\n",
    "def save_melspectrogram(log_S, output_path):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(log_S, sr=22050, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "extract_audio(r\"C:\\Users\\101ri\\OneDrive\\Desktop\\deep fake detector\\Notebook\\Celeb-real\\id0_0001.mp4\", \"audio.wav\")\n",
    "log_S, sr = audio_to_melspectrogram(\"audio.wav\")\n",
    "save_melspectrogram(log_S, \"melspectrogram.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb4f03-3908-4c1e-8649-da46bdbf9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde740c-3baf-439f-bb8e-15df81876ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d33211-a946-4160-a2b2-ae97ac6bce8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c90d07-000f-4db0-b104-0e1d74b92603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
